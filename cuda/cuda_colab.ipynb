{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# CUDA Convolution (Colab)\n\nThis notebook recreates the CUDA convolution code from the `cuda/` folder and runs it in Google Colab."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "!nvidia-smi"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Ghi chú GPU/Toolchain\nNếu gặp lỗi `the provided PTX was compiled with an unsupported toolchain`, hãy chạy cell kế tiếp để lấy compute capability và tắt PTX JIT. Cell compile bên dưới sẽ dùng đúng `SM`/`COMPUTE`."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os, subprocess\ncc = subprocess.check_output(\n    \"nvidia-smi --query-gpu=compute_cap --format=csv,noheader\",\n    shell=True, text=True\n).strip()\nsm = \"sm_\" + cc.replace(\".\", \"\")\ncompute = \"compute_\" + cc.replace(\".\", \"\")\nos.environ[\"SM\"] = sm\nos.environ[\"COMPUTE\"] = compute\nos.environ[\"CUDA_DISABLE_PTX_JIT\"] = \"1\"\nprint(\"Compute capability:\", cc, \"=\u003e\", sm, compute)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%%writefile funcs.h\n#ifndef FUNCS_H\n#define FUNCS_H\n\n#include \u003cstdio.h\u003e\n#include \u003cstdlib.h\u003e\n#include \u003cstdint.h\u003e\n#include \u003ctime.h\u003e\n\n#define CUDA_SAFE_CALL(call) {                                     \\\n    cudaError err = call;                                          \\\n    if (cudaSuccess != err) {                                      \\\n        fprintf(stderr, \"Cuda error in file \u0027%s\u0027 in line %i : %s.\\n\", \\\n                __FILE__, __LINE__, cudaGetErrorString(err));      \\\n        exit(EXIT_FAILURE);                                        \\\n    }                                                              \\\n}\n\n#define FRACTION_CEILING(numerator, denominator) ((numerator + denominator - 1) / (denominator))\n\ntypedef enum { RGB, GREY } color_t;\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nint write_all(int fd, uint8_t *buff, int size);\nint read_all(int fd, uint8_t *buff, int size);\nvoid Usage(int argc, char **argv, char **image, int *width, int *height, int *loops, color_t *imageType);\nuint64_t micro_time(void);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%%writefile funcs.c\n#include \u003cstdio.h\u003e\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n#include \u003cfcntl.h\u003e\n#include \u003cunistd.h\u003e\n#include \u003cstdint.h\u003e\n#include \u003cassert.h\u003e\n#include \u003csys/time.h\u003e\n#include \"funcs.h\"\n\nvoid Usage(int argc, char **argv, char **image, int *width, int *height, int *loops, color_t *imageType) {\n    if (argc == 6 \u0026\u0026 !strcmp(argv[5], \"grey\")) {\n        *image = (char *)malloc((strlen(argv[1]) + 1) * sizeof(char));\n        strcpy(*image, argv[1]);\n        *width = atoi(argv[2]);\n        *height = atoi(argv[3]);\n        *loops = atoi(argv[4]);\n        *imageType = GREY;\n    } else if (argc == 6 \u0026\u0026 !strcmp(argv[5], \"rgb\")) {\n        *image = (char *)malloc((strlen(argv[1]) + 1) * sizeof(char));\n        strcpy(*image, argv[1]);\n        *width = atoi(argv[2]);\n        *height = atoi(argv[3]);\n        *loops = atoi(argv[4]);\n        *imageType = RGB;\n    } else {\n        fprintf(stderr, \"Error Input!\\n%s image_name width height loops [rgb/grey].\\n\", argv[0]);\n        exit(EXIT_FAILURE);\n    }\n}\n\nint write_all(int fd, uint8_t* buff, int size) {\n    int n, sent;\n    for (sent = 0; sent \u003c size; sent += n)\n        if ((n = write(fd, buff + sent, size - sent)) == -1)\n            return -1;\n    return sent;\n}\n\nint read_all(int fd, uint8_t* buff, int size) {\n    int n, sent;\n    for (sent = 0; sent \u003c size; sent += n)\n        if ((n = read(fd, buff + sent, size - sent)) == -1)\n            return -1;\n    return sent;\n}\n\nuint64_t micro_time(void) {\n    struct timeval tv;\n    assert(gettimeofday(\u0026tv, NULL) == 0);\n    return (uint64_t)tv.tv_sec * 1000 * 1000 + (uint64_t)tv.tv_usec;\n}"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%%writefile cuda_convolute.h\n#ifndef CUDA_CONVOLUTE_H\n#define CUDA_CONVOLUTE_H\n\n#include \"funcs.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nvoid gpuConvolute(uint8_t *src, int width, int height, int loops, color_t imageType);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%%writefile cuda_convolute.cu\n#include \u003cstdio.h\u003e\n#include \u003cstdlib.h\u003e\n#include \"cuda_convolute.h\"\n#include \"funcs.h\"\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n\n#define BLOCK_SIZE 16\n\n__device__ __constant__ int c_kernel[9];\n\n__device__ __forceinline__ uint8_t div16_u8(int sum) {\n    return (uint8_t)(sum \u003e\u003e 4);\n}\n\n__global__ void kernel_conv_grey(const uint8_t *__restrict__ src, uint8_t *__restrict__ dst, int width, int height) {\n    __shared__ uint8_t tile[BLOCK_SIZE + 2][BLOCK_SIZE + 2];\n\n    int x = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n    int y = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n    int tx = threadIdx.x + 1;\n    int ty = threadIdx.y + 1;\n\n    if (x \u003c height \u0026\u0026 y \u003c width) {\n        tile[tx][ty] = src[width * x + y];\n    } else {\n        tile[tx][ty] = 0;\n    }\n\n    if (threadIdx.x == 0) {\n        tile[0][ty] = (x \u003e 0 \u0026\u0026 y \u003c width) ? src[width * (x - 1) + y] : 0;\n    }\n    if (threadIdx.x == BLOCK_SIZE - 1) {\n        tile[BLOCK_SIZE + 1][ty] = (x + 1 \u003c height \u0026\u0026 y \u003c width) ? src[width * (x + 1) + y] : 0;\n    }\n    if (threadIdx.y == 0) {\n        tile[tx][0] = (y \u003e 0 \u0026\u0026 x \u003c height) ? src[width * x + (y - 1)] : 0;\n    }\n    if (threadIdx.y == BLOCK_SIZE - 1) {\n        tile[tx][BLOCK_SIZE + 1] = (y + 1 \u003c width \u0026\u0026 x \u003c height) ? src[width * x + (y + 1)] : 0;\n    }\n\n    if (threadIdx.x == 0 \u0026\u0026 threadIdx.y == 0) {\n        tile[0][0] = (x \u003e 0 \u0026\u0026 y \u003e 0) ? src[width * (x - 1) + (y - 1)] : 0;\n    }\n    if (threadIdx.x == 0 \u0026\u0026 threadIdx.y == BLOCK_SIZE - 1) {\n        tile[0][BLOCK_SIZE + 1] = (x \u003e 0 \u0026\u0026 y + 1 \u003c width) ? src[width * (x - 1) + (y + 1)] : 0;\n    }\n    if (threadIdx.x == BLOCK_SIZE - 1 \u0026\u0026 threadIdx.y == 0) {\n        tile[BLOCK_SIZE + 1][0] = (x + 1 \u003c height \u0026\u0026 y \u003e 0) ? src[width * (x + 1) + (y - 1)] : 0;\n    }\n    if (threadIdx.x == BLOCK_SIZE - 1 \u0026\u0026 threadIdx.y == BLOCK_SIZE - 1) {\n        tile[BLOCK_SIZE + 1][BLOCK_SIZE + 1] =\n            (x + 1 \u003c height \u0026\u0026 y + 1 \u003c width) ? src[width * (x + 1) + (y + 1)] : 0;\n    }\n\n    __syncthreads();\n\n    if (x \u003e 0 \u0026\u0026 x \u003c height - 1 \u0026\u0026 y \u003e 0 \u0026\u0026 y \u003c width - 1) {\n        int sum = 0;\n        sum += tile[tx - 1][ty - 1] * c_kernel[0];\n        sum += tile[tx - 1][ty] * c_kernel[1];\n        sum += tile[tx - 1][ty + 1] * c_kernel[2];\n        sum += tile[tx][ty - 1] * c_kernel[3];\n        sum += tile[tx][ty] * c_kernel[4];\n        sum += tile[tx][ty + 1] * c_kernel[5];\n        sum += tile[tx + 1][ty - 1] * c_kernel[6];\n        sum += tile[tx + 1][ty] * c_kernel[7];\n        sum += tile[tx + 1][ty + 1] * c_kernel[8];\n        dst[width * x + y] = div16_u8(sum);\n    }\n}\n\n__global__ void kernel_conv_rgb(const uint8_t *__restrict__ src, uint8_t *__restrict__ dst, int width, int height) {\n    __shared__ uchar3 tile[BLOCK_SIZE + 2][BLOCK_SIZE + 2];\n\n    int x = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n    int y = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n    int tx = threadIdx.x + 1;\n    int ty = threadIdx.y + 1;\n\n    if (x \u003c height \u0026\u0026 y \u003c width) {\n        int idx = (x * width + y) * 3;\n        tile[tx][ty] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n    } else {\n        tile[tx][ty] = make_uchar3(0, 0, 0);\n    }\n\n    if (threadIdx.x == 0) {\n        if (x \u003e 0 \u0026\u0026 y \u003c width) {\n            int idx = ((x - 1) * width + y) * 3;\n            tile[0][ty] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[0][ty] = make_uchar3(0, 0, 0);\n        }\n    }\n    if (threadIdx.x == BLOCK_SIZE - 1) {\n        if (x + 1 \u003c height \u0026\u0026 y \u003c width) {\n            int idx = ((x + 1) * width + y) * 3;\n            tile[BLOCK_SIZE + 1][ty] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[BLOCK_SIZE + 1][ty] = make_uchar3(0, 0, 0);\n        }\n    }\n    if (threadIdx.y == 0) {\n        if (y \u003e 0 \u0026\u0026 x \u003c height) {\n            int idx = (x * width + (y - 1)) * 3;\n            tile[tx][0] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[tx][0] = make_uchar3(0, 0, 0);\n        }\n    }\n    if (threadIdx.y == BLOCK_SIZE - 1) {\n        if (y + 1 \u003c width \u0026\u0026 x \u003c height) {\n            int idx = (x * width + (y + 1)) * 3;\n            tile[tx][BLOCK_SIZE + 1] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[tx][BLOCK_SIZE + 1] = make_uchar3(0, 0, 0);\n        }\n    }\n\n    if (threadIdx.x == 0 \u0026\u0026 threadIdx.y == 0) {\n        if (x \u003e 0 \u0026\u0026 y \u003e 0) {\n            int idx = ((x - 1) * width + (y - 1)) * 3;\n            tile[0][0] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[0][0] = make_uchar3(0, 0, 0);\n        }\n    }\n    if (threadIdx.x == 0 \u0026\u0026 threadIdx.y == BLOCK_SIZE - 1) {\n        if (x \u003e 0 \u0026\u0026 y + 1 \u003c width) {\n            int idx = ((x - 1) * width + (y + 1)) * 3;\n            tile[0][BLOCK_SIZE + 1] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[0][BLOCK_SIZE + 1] = make_uchar3(0, 0, 0);\n        }\n    }\n    if (threadIdx.x == BLOCK_SIZE - 1 \u0026\u0026 threadIdx.y == 0) {\n        if (x + 1 \u003c height \u0026\u0026 y \u003e 0) {\n            int idx = ((x + 1) * width + (y - 1)) * 3;\n            tile[BLOCK_SIZE + 1][0] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[BLOCK_SIZE + 1][0] = make_uchar3(0, 0, 0);\n        }\n    }\n    if (threadIdx.x == BLOCK_SIZE - 1 \u0026\u0026 threadIdx.y == BLOCK_SIZE - 1) {\n        if (x + 1 \u003c height \u0026\u0026 y + 1 \u003c width) {\n            int idx = ((x + 1) * width + (y + 1)) * 3;\n            tile[BLOCK_SIZE + 1][BLOCK_SIZE + 1] = make_uchar3(src[idx], src[idx + 1], src[idx + 2]);\n        } else {\n            tile[BLOCK_SIZE + 1][BLOCK_SIZE + 1] = make_uchar3(0, 0, 0);\n        }\n    }\n\n    __syncthreads();\n\n    if (x \u003e 0 \u0026\u0026 x \u003c height - 1 \u0026\u0026 y \u003e 0 \u0026\u0026 y \u003c width - 1) {\n        int sum_r = 0, sum_g = 0, sum_b = 0;\n        const int *k = c_kernel;\n        uchar3 v;\n\n        v = tile[tx - 1][ty - 1]; sum_r += v.x * k[0]; sum_g += v.y * k[0]; sum_b += v.z * k[0];\n        v = tile[tx - 1][ty];     sum_r += v.x * k[1]; sum_g += v.y * k[1]; sum_b += v.z * k[1];\n        v = tile[tx - 1][ty + 1]; sum_r += v.x * k[2]; sum_g += v.y * k[2]; sum_b += v.z * k[2];\n        v = tile[tx][ty - 1];     sum_r += v.x * k[3]; sum_g += v.y * k[3]; sum_b += v.z * k[3];\n        v = tile[tx][ty];         sum_r += v.x * k[4]; sum_g += v.y * k[4]; sum_b += v.z * k[4];\n        v = tile[tx][ty + 1];     sum_r += v.x * k[5]; sum_g += v.y * k[5]; sum_b += v.z * k[5];\n        v = tile[tx + 1][ty - 1]; sum_r += v.x * k[6]; sum_g += v.y * k[6]; sum_b += v.z * k[6];\n        v = tile[tx + 1][ty];     sum_r += v.x * k[7]; sum_g += v.y * k[7]; sum_b += v.z * k[7];\n        v = tile[tx + 1][ty + 1]; sum_r += v.x * k[8]; sum_g += v.y * k[8]; sum_b += v.z * k[8];\n\n        int out_idx = (x * width + y) * 3;\n        dst[out_idx] = div16_u8(sum_r);\n        dst[out_idx + 1] = div16_u8(sum_g);\n        dst[out_idx + 2] = div16_u8(sum_b);\n    }\n}\n\r\nextern \"C\" void gpuConvolute(uint8_t *src, int width, int height, int loops, color_t imageType) {\n    uint8_t *d_src, *d_dst, *tmp;\n    size_t bytes = (imageType == GREY) ? (size_t)height * width : (size_t)height * width * 3;\n\n    static const int h_kernel[9] = {1, 2, 1, 2, 4, 2, 1, 2, 1};\n    CUDA_SAFE_CALL(cudaMemcpyToSymbol(c_kernel, h_kernel, sizeof(h_kernel)));\n\n    CUDA_SAFE_CALL(cudaMalloc(\u0026d_src, bytes * sizeof(uint8_t)));\n    CUDA_SAFE_CALL(cudaMalloc(\u0026d_dst, bytes * sizeof(uint8_t)));\n\n    CUDA_SAFE_CALL(cudaMemcpy(d_src, src, bytes, cudaMemcpyHostToDevice));\n    CUDA_SAFE_CALL(cudaMemset(d_dst, 0, bytes));\n\n    const int blockSize = BLOCK_SIZE;\n    dim3 block(blockSize, blockSize);\n    dim3 grid_grey(FRACTION_CEILING(height, blockSize), FRACTION_CEILING(width, blockSize));\n    dim3 grid_rgb(FRACTION_CEILING(height, blockSize), FRACTION_CEILING(width, blockSize));\n\n    for (int t = 0; t \u003c loops; t++) {\n        if (imageType == GREY) {\n            kernel_conv_grey\u003c\u003c\u003cgrid_grey, block\u003e\u003e\u003e(d_src, d_dst, width, height);\n        } else if (imageType == RGB) {\n            kernel_conv_rgb\u003c\u003c\u003cgrid_rgb, block\u003e\u003e\u003e(d_src, d_dst, width, height);\n        }\n\n        tmp = d_src;\n        d_src = d_dst;\n        d_dst = tmp;\n    }\n\n    CUDA_SAFE_CALL(cudaGetLastError());\n    CUDA_SAFE_CALL(cudaDeviceSynchronize());\n\n    if (loops % 2 == 0) {\n        CUDA_SAFE_CALL(cudaMemcpy(src, d_src, bytes, cudaMemcpyDeviceToHost));\n    } else {\n        CUDA_SAFE_CALL(cudaMemcpy(src, d_dst, bytes, cudaMemcpyDeviceToHost));\n    }\n\n    CUDA_SAFE_CALL(cudaFree(d_src));\n    CUDA_SAFE_CALL(cudaFree(d_dst));\n}\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%%writefile main.c\n#include \u003cstdio.h\u003e\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n#include \u003cfcntl.h\u003e\n#include \u003cunistd.h\u003e\n#include \u003cstdint.h\u003e\n#include \"cuda_convolute.h\"\n#include \"funcs.h\"\n\nint main(int argc, char** argv) {\n    int fd, width, height, loops;\n    char *image;\n    color_t imageType;\n\n    Usage(argc, argv, \u0026image, \u0026width, \u0026height, \u0026loops, \u0026imageType);\n\n    uint8_t *src = NULL;\n    uint64_t c = micro_time();\n\n    if ((fd = open(image, O_RDONLY)) \u003c 0) {\n        fprintf(stderr, \"cannot open %s\\n\", argv[1]);\n        return EXIT_FAILURE;\n    }\n    size_t bytes = (imageType == GREY) ? (size_t)height * width : (size_t)height * width * 3;\n    src = (uint8_t *)calloc(bytes, sizeof(uint8_t));\n    read_all(fd, src, (int)bytes);\n    close(fd);\n\n    gpuConvolute(src, width, height, loops, imageType);\n\n    int fd_out;\n    char *outImage = (char*)malloc((strlen(image) + 9) * sizeof(char));\n    strcpy(outImage, \"blur_\");\n    strcat(outImage, image);\n    if ((fd_out = open(outImage, O_CREAT | O_WRONLY, 0644)) == -1) {\n        fprintf(stderr, \"cannot open-create %s\\n\", outImage);\n        return EXIT_FAILURE;\n    }\n    write_all(fd_out, src, (int)bytes);\n    close(fd_out);\n    free(outImage);\n\n    c = micro_time() - c;\n    double million = 1000 * 1000;\n    fprintf(stdout, \"Execution time: %.3f sec\\n\", c / million);\n\n    free(src);\n    return EXIT_SUCCESS;\n}"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Compile (SASS only for your GPU)\n!rm -f *.o cuda_conv\n!nvcc -O3 -gencode arch=$COMPUTE,code=$SM -c cuda_convolute.cu\n!gcc -O3 -c main.c\n!gcc -O3 -c funcs.c\n!nvcc -O3 -gencode arch=$COMPUTE,code=$SM -o cuda_conv main.o funcs.o cuda_convolute.o"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Upload a .raw file from your machine\nfrom google.colab import files\nfiles.upload()"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Run (edit these variables to match your input)\nimage = \"waterfall_grey_1920_2520.raw\"\nwidth = 1920\nheight = 2520\nloops = 50\nmode = \"grey\"  # \"grey\" or \"rgb\"\n\n!./cuda_conv $image $width $height $loops $mode"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "metadata":  {

                                   },
                      "execution_count":  null,
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Download the output\nfrom google.colab import files\nfiles.download(\"blur_\" + image)"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "name":  "python"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
